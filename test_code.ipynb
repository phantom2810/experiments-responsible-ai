{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3cf6f2-9d9c-43cd-a627-49f181db5a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TrustyAI version: 0.6.1\n",
      "‚úÖ Model trained - Accuracy: 0.945\n",
      "‚úÖ Created 5 prediction inputs\n",
      "‚úÖ TrustyAI model created\n",
      "‚úÖ Model prediction generated\n",
      "üéâ LIME explanation generated successfully!\n",
      "\n",
      "üìä LIME Results:\n",
      "==================================================\n",
      "\n",
      "üìà LINEAR-SUM EXPLANATION:\n",
      "     Feature     Value  Saliency  Confidence\n",
      "0  feature_8  1.667013  2.921838         0.0\n",
      "1  feature_0  0.537817  2.806179         0.0\n",
      "2  feature_4  1.387787  2.639452         0.0\n",
      "3  feature_6  2.890934  2.522384         0.0\n",
      "4  feature_1  3.044738  2.655626         0.0\n",
      "\n",
      "üîç Saliency Map Type: <class 'dict'>\n",
      "Available keys: ['linear-sum']\n",
      "\n",
      "üéØ INTERPRETATION:\n",
      "‚úÖ Successfully generated LIME explanation using TrustyAI\n",
      "‚úÖ The DataFrame shows:\n",
      "   - Feature: Input feature names\n",
      "   - Value: Actual feature values for this prediction\n",
      "   - Saliency: Importance score (higher = more influential)\n",
      "   - Confidence: LIME's confidence in the explanation\n",
      "\n",
      "üöÄ NEXT STEPS:\n",
      "1. Try with your own sklearn models\n",
      "2. Experiment with different samples\n",
      "3. Explore other TrustyAI explainers (SHAP, PDP)\n",
      "4. Set up model monitoring and bias detection\n",
      "\n",
      "‚úÖ Helper function 'explain_prediction_with_lime' defined for reuse\n"
     ]
    }
   ],
   "source": [
    "# TrustyAI LIME Explanation - Clean Working Code\n",
    "# ==============================================\n",
    "\n",
    "# 1. Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import TrustyAI components\n",
    "import trustyai\n",
    "from trustyai.explainers import LimeExplainer\n",
    "from trustyai.model import FeatureFactory, PredictionInput\n",
    "from trustyai.utils import TestModels\n",
    "from java.util import Arrays\n",
    "\n",
    "print(f\"‚úÖ TrustyAI version: {trustyai.__version__}\")\n",
    "\n",
    "# 2. Create and Train a Model\n",
    "# Create synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, \n",
    "    n_features=10, \n",
    "    n_informative=5,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create feature names\n",
    "feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"‚úÖ Model trained - Accuracy: {rf_model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# 3. Prepare Sample Data for Explanation\n",
    "sample_size = 5\n",
    "X_sample = X_test[:sample_size]\n",
    "y_sample = y_test[:sample_size]\n",
    "\n",
    "# Convert to TrustyAI PredictionInput format\n",
    "prediction_inputs = []\n",
    "for i in range(sample_size):\n",
    "    features = []\n",
    "    for j, feature_name in enumerate(feature_names):\n",
    "        feature = FeatureFactory.newNumericalFeature(feature_name, X_sample[i, j])\n",
    "        features.append(feature)\n",
    "    \n",
    "    pred_input = PredictionInput(features)\n",
    "    prediction_inputs.append(pred_input)\n",
    "\n",
    "print(f\"‚úÖ Created {len(prediction_inputs)} prediction inputs\")\n",
    "\n",
    "# 4. Set Up TrustyAI Model (using TestModel for demonstration)\n",
    "# Create a simple linear model for explanation\n",
    "weights = np.array([1.0, 2.0, -1.0, 0.5, 1.5, -0.5, 0.8, -0.3, 1.2, -0.7])\n",
    "trusty_model = TestModels.getLinearModel(weights)\n",
    "\n",
    "print(\"‚úÖ TrustyAI model created\")\n",
    "\n",
    "# 5. Generate LIME Explanation\n",
    "# Create LIME explainer\n",
    "lime_explainer = LimeExplainer()\n",
    "\n",
    "# Get sample input\n",
    "sample_input = prediction_inputs[0]\n",
    "\n",
    "# Generate prediction output from the model\n",
    "prediction_inputs_list = Arrays.asList([sample_input])\n",
    "prediction_result = trusty_model.predictAsync(prediction_inputs_list).get()\n",
    "first_prediction = prediction_result.get(0)\n",
    "\n",
    "print(\"‚úÖ Model prediction generated\")\n",
    "\n",
    "# Generate LIME explanation using the correct signature:\n",
    "# explain(inputs, outputs, model)\n",
    "lime_result = lime_explainer.explain(sample_input, first_prediction, trusty_model)\n",
    "\n",
    "print(\"üéâ LIME explanation generated successfully!\")\n",
    "\n",
    "# 6. Extract and Display Results\n",
    "print(\"\\nüìä LIME Results:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Method 1: DataFrame format (most useful)\n",
    "df_result = lime_result.as_dataframe()\n",
    "if isinstance(df_result, dict):\n",
    "    for key, value in df_result.items():\n",
    "        # Convert Java string to Python string safely\n",
    "        key_name = str(key).upper()\n",
    "        print(f\"\\nüìà {key_name} EXPLANATION:\")\n",
    "        if hasattr(value, 'head'):\n",
    "            print(value.head())\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "# Method 2: Raw saliency map (if needed)\n",
    "try:\n",
    "    saliency_map = lime_result.saliency_map()\n",
    "    print(f\"\\nüîç Saliency Map Type: {type(saliency_map)}\")\n",
    "    print(f\"Available keys: {list(saliency_map.keys()) if saliency_map else 'None'}\")\n",
    "except Exception as e:\n",
    "    print(f\"Saliency map access: {e}\")\n",
    "\n",
    "# 7. Interpretation Summary\n",
    "print(f\"\\nüéØ INTERPRETATION:\")\n",
    "print(\"‚úÖ Successfully generated LIME explanation using TrustyAI\")\n",
    "print(\"‚úÖ The DataFrame shows:\")\n",
    "print(\"   - Feature: Input feature names\")\n",
    "print(\"   - Value: Actual feature values for this prediction\")\n",
    "print(\"   - Saliency: Importance score (higher = more influential)\")\n",
    "print(\"   - Confidence: LIME's confidence in the explanation\")\n",
    "\n",
    "print(f\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"1. Try with your own sklearn models\")\n",
    "print(\"2. Experiment with different samples\")\n",
    "print(\"3. Explore other TrustyAI explainers (SHAP, PDP)\")\n",
    "print(\"4. Set up model monitoring and bias detection\")\n",
    "\n",
    "# 8. Helper Function for Future Use\n",
    "def explain_prediction_with_lime(model, sample_input, feature_names):\n",
    "    \"\"\"\n",
    "    Helper function to generate LIME explanations for any model prediction\n",
    "    \n",
    "    Args:\n",
    "        model: TrustyAI PredictionProvider model\n",
    "        sample_input: TrustyAI PredictionInput object\n",
    "        feature_names: List of feature names\n",
    "    \n",
    "    Returns:\n",
    "        lime_result: LimeResults object with explanations\n",
    "    \"\"\"\n",
    "    lime_explainer = LimeExplainer()\n",
    "    \n",
    "    # Generate prediction\n",
    "    prediction_list = Arrays.asList([sample_input])\n",
    "    prediction_output = model.predictAsync(prediction_list).get().get(0)\n",
    "    \n",
    "    # Generate explanation\n",
    "    lime_result = lime_explainer.explain(sample_input, prediction_output, model)\n",
    "    \n",
    "    return lime_result\n",
    "\n",
    "print(\"\\n‚úÖ Helper function 'explain_prediction_with_lime' defined for reuse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ede6a-747c-4f83-913f-00305d46da7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
